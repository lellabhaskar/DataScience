{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6p_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5T3Z+7kyqTsQdBzFiQtd3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lellabhaskar/DataScience/blob/main/6p_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP stands for Natural Language Processing\n",
        "# For Example: \n",
        "# Natural Languages are any thing that human being speaks,read or write. \n",
        "# not only Humanbeing ,if your develop NLP for parrot that also be understand"
      ],
      "metadata": {
        "id": "_cXjKhX-UG3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "Xi_t_x7D-GsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8197d17c-5b1d-49d9-a768-e287a71d4287"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine Learing works only for Numbers.\n",
        "# y=mx +c  or   y= weights*x + bias"
      ],
      "metadata": {
        "id": "b4s5KOoEM5ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to convert words/letters/sentences into mathematical entities are Numbers, Vectors, Tensor"
      ],
      "metadata": {
        "id": "fzTcEtrDNJxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP used Libraries are -> Spacy, Textacy, NLTK, etc..."
      ],
      "metadata": {
        "id": "xITt6l54NZ1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install spacy library on local machine or web server\n",
        "# pip install -U spacy\n",
        "# python -m spacy download en\n",
        "# python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "guUTLDVBNj9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "p10QEQt5JTlj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to download Dictionary\n",
        "# Dictionary created by language Experts, we don't create a new dictionary from scratch\n",
        "dictionary = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "Y4eFt8jmOWZT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Mary had a little lamb, little lamb, little lamb!'\n",
        "tokens = dictionary(text)  # Tokens are broken down pieces of text\n",
        "# Example of Tokens:\n",
        "# Document->Pages-> Paragraphs-> Sentences -> Words -> Letters\n",
        "# Above refer to the subject called Compiler Design -> Break down things into Trees and parse the tree "
      ],
      "metadata": {
        "id": "h44FEWS6O9zp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh26uMFcPAqY",
        "outputId": "55376ca0-9081-4e7f-9d73-1452cda05541"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mary had a little lamb, little lamb, little lamb!"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8_OQ6Tf1Qoft",
        "outputId": "3c8a8b9f-67a7-43af-e5cb-4c5fe264ba08"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Mary had a little lamb, little lamb, little lamb!'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# difference of tokens and text \n",
        "# text is string\n",
        "# tokens ->This isn't a String anymore, this is a List of tokens"
      ],
      "metadata": {
        "id": "rj2QYJoKQqYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "q3Nv2Pp-RI5b",
        "outputId": "09e4faed-1833-4a23-e2e0-dbc78ca46745"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX6h_7UQRPRS",
        "outputId": "e78561ff-829d-4f38-f9bd-eff56f64393e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "had"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in tokens:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4joNPa5RR5W",
        "outputId": "1eeb8415-861a-4a6a-a29b-31697dbc5d19"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mary\n",
            "had\n",
            "a\n",
            "little\n",
            "lamb\n",
            ",\n",
            "little\n",
            "lamb\n",
            ",\n",
            "little\n",
            "lamb\n",
            "!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find the functions in python \n",
        "dir(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6My51D1vR-NV",
        "outputId": "d9de4aac-0c6c-42ce-8f37-a6186f45a6b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_',\n",
              " '__bytes__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pyx_vtable__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__unicode__',\n",
              " '_bulk_merge',\n",
              " '_py_tokens',\n",
              " '_realloc',\n",
              " '_vector',\n",
              " '_vector_norm',\n",
              " 'cats',\n",
              " 'char_span',\n",
              " 'count_by',\n",
              " 'doc',\n",
              " 'ents',\n",
              " 'extend_tensor',\n",
              " 'from_array',\n",
              " 'from_bytes',\n",
              " 'from_disk',\n",
              " 'get_extension',\n",
              " 'get_lca_matrix',\n",
              " 'has_extension',\n",
              " 'has_vector',\n",
              " 'is_nered',\n",
              " 'is_parsed',\n",
              " 'is_sentenced',\n",
              " 'is_tagged',\n",
              " 'lang',\n",
              " 'lang_',\n",
              " 'mem',\n",
              " 'merge',\n",
              " 'noun_chunks',\n",
              " 'noun_chunks_iterator',\n",
              " 'print_tree',\n",
              " 'remove_extension',\n",
              " 'retokenize',\n",
              " 'sentiment',\n",
              " 'sents',\n",
              " 'set_extension',\n",
              " 'similarity',\n",
              " 'tensor',\n",
              " 'text',\n",
              " 'text_with_ws',\n",
              " 'to_array',\n",
              " 'to_bytes',\n",
              " 'to_disk',\n",
              " 'to_json',\n",
              " 'to_utf8_array',\n",
              " 'user_data',\n",
              " 'user_hooks',\n",
              " 'user_span_hooks',\n",
              " 'user_token_hooks',\n",
              " 'vector',\n",
              " 'vector_norm',\n",
              " 'vocab']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how to check individual token\n",
        "dir(tokens[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTG7XcdHVpAS",
        "outputId": "d1ef33ea-983f-426f-c889-663a6231426a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_',\n",
              " '__bytes__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pyx_vtable__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__unicode__',\n",
              " 'ancestors',\n",
              " 'check_flag',\n",
              " 'children',\n",
              " 'cluster',\n",
              " 'conjuncts',\n",
              " 'dep',\n",
              " 'dep_',\n",
              " 'doc',\n",
              " 'ent_id',\n",
              " 'ent_id_',\n",
              " 'ent_iob',\n",
              " 'ent_iob_',\n",
              " 'ent_kb_id',\n",
              " 'ent_kb_id_',\n",
              " 'ent_type',\n",
              " 'ent_type_',\n",
              " 'get_extension',\n",
              " 'has_extension',\n",
              " 'has_vector',\n",
              " 'head',\n",
              " 'i',\n",
              " 'idx',\n",
              " 'is_alpha',\n",
              " 'is_ancestor',\n",
              " 'is_ascii',\n",
              " 'is_bracket',\n",
              " 'is_currency',\n",
              " 'is_digit',\n",
              " 'is_left_punct',\n",
              " 'is_lower',\n",
              " 'is_oov',\n",
              " 'is_punct',\n",
              " 'is_quote',\n",
              " 'is_right_punct',\n",
              " 'is_sent_start',\n",
              " 'is_space',\n",
              " 'is_stop',\n",
              " 'is_title',\n",
              " 'is_upper',\n",
              " 'lang',\n",
              " 'lang_',\n",
              " 'left_edge',\n",
              " 'lefts',\n",
              " 'lemma',\n",
              " 'lemma_',\n",
              " 'lex_id',\n",
              " 'like_email',\n",
              " 'like_num',\n",
              " 'like_url',\n",
              " 'lower',\n",
              " 'lower_',\n",
              " 'morph',\n",
              " 'n_lefts',\n",
              " 'n_rights',\n",
              " 'nbor',\n",
              " 'norm',\n",
              " 'norm_',\n",
              " 'orth',\n",
              " 'orth_',\n",
              " 'pos',\n",
              " 'pos_',\n",
              " 'prefix',\n",
              " 'prefix_',\n",
              " 'prob',\n",
              " 'rank',\n",
              " 'remove_extension',\n",
              " 'right_edge',\n",
              " 'rights',\n",
              " 'sent',\n",
              " 'sent_start',\n",
              " 'sentiment',\n",
              " 'set_extension',\n",
              " 'shape',\n",
              " 'shape_',\n",
              " 'similarity',\n",
              " 'string',\n",
              " 'subtree',\n",
              " 'suffix',\n",
              " 'suffix_',\n",
              " 'tag',\n",
              " 'tag_',\n",
              " 'tensor',\n",
              " 'text',\n",
              " 'text_with_ws',\n",
              " 'vector',\n",
              " 'vector_norm',\n",
              " 'vocab',\n",
              " 'whitespace_']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[0].vector  # expecting a list of numbers \n",
        "# tokens[0].tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xFqTWgtV_oE",
        "outputId": "46353266-9e0f-49f5-929a-bab44a428294"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.4509495 , -1.5681124 , -1.9461675 ,  1.839561  ,  3.4780774 ,\n",
              "        2.524608  ,  0.33326906, -1.5484917 ,  7.4678564 ,  0.60519946,\n",
              "        3.1377375 ,  0.7935887 ,  0.58354187, -0.2661229 , -2.226547  ,\n",
              "        0.1650516 ,  0.19616508,  0.44295195, -0.6433928 , -1.1714629 ,\n",
              "       -1.6007192 , -2.0752583 ,  0.25768483, -3.8029935 , -1.9360929 ,\n",
              "        0.03117523, -3.39713   , -3.5714767 , -0.60103   , -0.9838464 ,\n",
              "        2.1978376 , -3.2238326 , -0.32594115,  0.8433224 ,  7.957924  ,\n",
              "       -0.03823709, -0.24748272, -1.4541488 , -1.1449388 ,  0.5361395 ,\n",
              "        0.31154394, -1.2105138 ,  3.0802765 , -2.5341787 , -0.34331483,\n",
              "        2.37043   , -1.4925265 , -0.588382  , -0.01588336,  6.6166472 ,\n",
              "       -2.1355598 , -1.0340636 , -2.2041569 ,  0.04030764, -5.109659  ,\n",
              "        2.916152  ,  1.064828  ,  1.0461608 ,  2.3962123 , -2.4949212 ,\n",
              "       -2.0643337 , -0.4496295 , -1.3907826 , -1.2317047 ,  1.3493019 ,\n",
              "        1.4107083 , -1.2005286 , -2.8885674 , -1.2789047 ,  0.61199975,\n",
              "       -0.8376126 ,  3.2062962 , -2.1587226 ,  1.1197324 ,  0.09724939,\n",
              "       -3.640162  ,  1.962763  ,  0.34758192, -2.1748543 , -0.2750789 ,\n",
              "        0.07716727, -2.0101733 , -0.9635895 ,  0.61195964,  5.3732533 ,\n",
              "        4.4804792 , -0.41252273, -1.9761388 ,  2.0547218 ,  0.26199448,\n",
              "       -1.804138  , -1.255786  ,  0.35005945,  4.068995  ,  2.9035487 ,\n",
              "        0.7118103 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[0].text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yngaVOdDXdza",
        "outputId": "e27348f8-f9a8-43c5-96cc-e209d57d0c5b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Mary'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[0].shape  # word space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6yMpUT6Xim6",
        "outputId": "1b161bbe-af0c-4066-e910-849a54580be2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10887629174180191697"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# regular expression are used to find the any pattern\n",
        "# https://regexr.com/"
      ],
      "metadata": {
        "id": "62LHUWbCXvMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for example purpose need more huge text in notepad \n",
        "# upload text.txt file in google colab\n",
        "# https://theoatmeal.com/comics/mantis_shrimp"
      ],
      "metadata": {
        "id": "2sR9mVG9YaRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS_qCufSfkXO",
        "outputId": "58fbb366-0f5b-4445-a94f-973aeb8d1d94"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  text.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "f = open('text.txt','rt')\n",
        "content = f.read()\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "tokens = nlp(content) # Text-> Tokens-> POS tagging is complete as per SPACY\n",
        "len(tokens) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9FbjniZcQBH",
        "outputId": "527f268f-a56e-4b64-83d8-7a1f3894ee94"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5412"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we saw 2 kind of errors -> Encoding Errors \n",
        "# Encoding/Decoding : https://www.geeksforgeeks.org/python-strings-decode-method/"
      ],
      "metadata": {
        "id": "Ui_mX5nke3n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Encoding is converting one format into another\n",
        "Decoding is reverse engineering encoded format\n",
        "\n",
        "Encryption's objective is to Hide or protect information\n",
        "Encoding is to process the information Better "
      ],
      "metadata": {
        "id": "Jk_ef4BUhEDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding examples\n",
        "\n",
        "1.Converting from one language into another\n",
        "2.Audio raw wave file into MP3\n",
        "3.PNG to JPG"
      ],
      "metadata": {
        "id": "Q3_CZbADiWl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://www.asciitable.com/"
      ],
      "metadata": {
        "id": "_N_HUe3fqmjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fHQr_lMsq9Qo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}